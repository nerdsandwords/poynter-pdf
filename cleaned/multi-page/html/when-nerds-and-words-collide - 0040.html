<body>
 <h3 id="bookmark0">
  Driving Defensively Through Data’s Dangers
 </h3>
 <p>
  <strong>
   By Dwight Morris
  </strong>
 </p>
 <p>
  For 18 of the past 22 years I have struggled to merge traditional reporting with in-depth data analysis. Plucked from graduate school in 1977 by
  <em>
   The New York Times
  </em>
  to help an aging, irascible, and, to my mind, brilliant editor named Henry Lieberman bring what was then known as “precision journalism” to the paper, much of my career has been devoted to the design and execution of large data-driven investigative projects. Along the way I have been fortunate to have a hand in the development of one Pulitzer Prize winner at the
  <em>
   Journal-Constitution
  </em>
  in Atlanta and a second Pulitzer finalist at the
  <em>
   Los Angeles Times.
  </em>
 </p>
 <p>
  If there is one thing I can say with absolute certainty, it is that I despise the phrase “computer assisted reporting,” hereafter grudgingly referred to as CAR. My loathing of the phrase springs from the fact that its continued use serves to over-emphasize the importance of machines and software while largely ignoring the truly important factors that determine the success of any CAR project - critical thinking about one’s analysis plan and the ability to recognize and fix data problems before they become the subject of a retraction.
 </p>
 <p>
  Truth be told, I’m also not that wild about the phrase “precision journalism.” It strikes me as an unintentional slap at those who are not terribly computer literate but who nevertheless do their utmost to be precise at all times. As an alternative to both these labels, I offer the term “data-based reporting,” which places the emphasis where I believe it belongs - on understanding and explaining the mountains of information routinely used by government agencies at all levels in ways that impact public life. If as journalists you do nothing else, at least consider the following intellectual roadmap for getting started.
 </p>
 <h4 id="bookmark1">
  Recognize that data are always dirty
 </h4>
 <p>
  The first step in becoming a good data-based reporter is to recognize that we are largely powerless over those who construct and provide data. Databases are built to specifications that meet the needs of a particular government agency, which may or may not suit our reportorial needs. Among the linchpins in this database building process are data-entry operators who frequently know little about and could not care less about what they are keying. Their productivity, and therefore then job performance, is measured by how many keystrokes per hour they produce on average.
 </p>
 <p>
  As a result, if there is one thing you can be sure of, it is that all databases are dirty. As I write this, the Federal Election Commission’s campaign contribution database contains roughly $2 million more in soft money donations to the 1998 Republican House-Senate Dinner Committee than it should. A data-entry operator either ignored or misunderstood how memo entries should be handled and, as a result, double-keyed dozens of contributions. That error has gone unnoticed by the FEC for more than six months.
 </p>
 <p>
  Far from being the exception, this is the unfortunate norm. Once errors are pointed out or discovered, the FEC takes fairly
 </p>
 <p>
  swift action to correct them, but over the past year literally thousands of factual errors, both large and small, have been corrected at one point or another. If you happen to be one of the hundreds of journalists who uses the data for primary research on stories each year, you had better have a sufficient understanding of the rules governing contributions to spot potential errors and fix them.
 </p>
 <p>
  Whether any error in the FEC data is significant beyond the natural journalistic desire for complete accuracy depends largely upon whether one is writing about how much a particular committee or candidate raised or writing about how much soft money was raised by all party committees. In general, data problems are most acute when one is writing about a restricted “universe;” the smaller the focus of the story, the more critical the need for correcting even small errors.
 </p>
 <p>
  For example, following each of the past four election cycles I have examined federal donation records to determine how many Americans violated the $25,000 annual limit on contributions imposed as part of the post-Watergate reforms. While there have been well over 150 individuals who appeared to be in violation of federal contribution limits in each of the last two election cycles, roughly 25 percent of those scofflaws proved to be false positives due to reporting errors by party and candidate committees, as well as data entry errors by the FEC.
 </p>
 <p>
  During the 1992 election cycle, three members of one Chicago family appeared over the limit until we discovered that the National Republican Senatorial Committee had inadvertently filed three copies of the same page of one of its reports. The FEC dutifully keyed all the pages it received without noticing the duplicate page numbers.
 </p>
 <p>
  As a result, a single $10,000 donation by each of the three individuals appeared in the FEC database as three $10,000 donations by each. Without rigid rules dictating that we double check all donations attributed to our targets, we easily could have branded three innocent people on the front page of the
  <em>
   Los Angeles Times.
  </em>
 </p>
 <h4 id="bookmark2">
  Recognize that data you need may be missing
 </h4>
 <p>
  Lest one believe that the FEC is particularly incompetent, consider the case of the Resolution Trust Corporation (RTC), the now-defunct agency set up to dispose of assets originally held by failed savings and loans. In August 1991, Bob Rosenblatt, a reporter in the
  <em>
   Los Angeles Times’
  </em>
  Washington bureau, and I decided to assess the performance of the RTC in recouping for
 </p>
 <div>
  <img src="when-nerds-and-words-collide - 0040_files/when-nerds-and-words-collide - 0040-1.jpg" style="width:64pt;height:84pt;"/>
  <p>
   Dwight L. Morris is president of Campaign Study Group (CSG), a for-profit media consulting firm specializing in campaign finance analysis. During the 1996 and 1998 campaigns, he wrote Money Talk$, a column on campaign finance for wash-ingtonpost.com. For six years prior to founding CSG, Morris was editor for special investigations at the
   <em>
    Los Angeles Times'
   </em>
   Washington bureau, where he designed numerous CAR projects.
  </p>
 </div>
 <div>
  <p>
   <strong>
    35
   </strong>
  </p>
 </div>
</body>
